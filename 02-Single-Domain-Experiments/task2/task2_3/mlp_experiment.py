"""
MLPåŒè·¯å¾„è¾“å…¥å¯¹æ¯”å®éªŒ
"""
import os
import sys
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

import pandas as pd
import numpy as np
from sklearn.neural_network import MLPClassifier
from common_utils import (
    load_datasets, align_and_prepare_dual_path, preprocess_dual_path_data,
    split_train_test, evaluate_predictions, save_results_to_csv, create_summary_csv
)


def create_mlp_model():
    """åˆ›å»ºMLPæ¨¡å‹"""
    model = MLPClassifier(
        hidden_layer_sizes=(512, 256, 128),
        activation='relu',
        solver='adam',
        alpha=0.001,
        batch_size=32,
        learning_rate='adaptive',
        learning_rate_init=0.001,
        max_iter=500,
        random_state=42,
        early_stopping=True,
        validation_fraction=0.1,
        n_iter_no_change=10
    )
    return model


def train_and_evaluate_mlp(X_train, X_test, y_train, y_test, dataset_type, size_type, output_dir):
    """è®­ç»ƒå’Œè¯„ä¼°MLPæ¨¡å‹"""
    print(f"å¼€å§‹è®­ç»ƒMLPæ¨¡å‹ - åŒè·¯å¾„è¾“å…¥ - {size_type}")
    
    # åˆ›å»ºæ¨¡å‹
    print("åˆ›å»ºMLPæ¨¡å‹...")
    model = create_mlp_model()
    
    # è®­ç»ƒæ¨¡å‹
    print("å¼€å§‹è®­ç»ƒMLPæ¨¡å‹...")
    model.fit(X_train, y_train)
    print("MLPæ¨¡å‹è®­ç»ƒå®Œæˆ")
    
    # é¢„æµ‹
    print("è¿›è¡ŒMLPé¢„æµ‹...")
    y_pred = model.predict(X_test)
    print("é¢„æµ‹å®Œæˆ")
    
    # è¯„ä¼°
    print("è¯„ä¼°MLPæ¨¡å‹...")
    results = evaluate_predictions(y_test, y_pred)
    
    print(f"MLPæ¨¡å‹æ€§èƒ½ - {size_type}:")
    print(f"   å‡†ç¡®ç‡: {results['accuracy']:.4f}")
    print(f"   ç²¾ç¡®ç‡: {results['precision']:.4f}")
    print(f"   å¬å›ç‡: {results['recall']:.4f}")
    print(f"   F1åˆ†æ•°: {results['f1_score']:.4f}")
    
    # ä¿å­˜ç»“æœ
    save_results_to_csv(results, 'MLP', 'dual_path', size_type, output_dir)
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹MLPåŒè·¯å¾„è¾“å…¥å¯¹æ¯”å®éªŒ")
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent / 'results'
    output_dir.mkdir(exist_ok=True)
    
    # åŠ è½½æ•°æ®é›†
    datasets = load_datasets()
    
    all_results = []
    
    # å¯¹æ¯ä¸ªæ•°æ®é›†å¤§å°è¿›è¡Œå®éªŒ
    for size_type in ['035', '05']:
        print(f"\n{'='*60}")
        print(f"ğŸ¯ å¤„ç†æ•°æ®é›†å¤§å°: {size_type}")
        print(f"{'='*60}")
        
        # è·å–æ•°æ®
        data1 = datasets['data1'][size_type]
        data2 = datasets['data2'][size_type]
        
        # å¯¹é½å’Œå‡†å¤‡åŒè·¯å¾„æ•°æ®
        raw_data, feat_data, labels = align_and_prepare_dual_path(data1, data2)
        
        # é¢„å¤„ç†æ•°æ®
        X, y, label_encoder, raw_scaler, feat_scaler = preprocess_dual_path_data(raw_data, feat_data, labels)
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = split_train_test(X, y, test_size=0.2, random_state=42)
        
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬")
        print(f"   ç‰¹å¾ç»´åº¦: {X_train.shape[1]}")
        print(f"   ç±»åˆ«æ•°: {len(label_encoder.classes_)}")
        
        # è®­ç»ƒå’Œè¯„ä¼°MLP
        results = train_and_evaluate_mlp(X_train, X_test, y_train, y_test, 'dual_path', size_type, output_dir)
        all_results.append(results)
    
    # åˆ›å»ºæ±‡æ€»CSV
    print(f"\nğŸ“Š åˆ›å»ºæ±‡æ€»ç»“æœ...")
    create_summary_csv(output_dir)
    
    print(f"\nâœ… MLPåŒè·¯å¾„è¾“å…¥å¯¹æ¯”å®éªŒå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")


if __name__ == "__main__":
    main()
